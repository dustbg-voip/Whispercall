import Foundation
import WebRTC
import Combine
import AVFoundation

final class WebRTCManager: NSObject, ObservableObject {
    static let shared = WebRTCManager()
    
    private let factory = RTCPeerConnectionFactory()
    private var peerConnection: RTCPeerConnection?
    
    // –ê—É–¥–∏–æ —Ç—Ä–µ–∫–∏
    private(set) var localAudioTrack: RTCAudioTrack?
    private(set) var remoteAudioTrack: RTCAudioTrack?
    
    // –í–∏–¥–µ–æ —Ç—Ä–µ–∫–∏
    private(set) var localVideoTrack: RTCVideoTrack?
    private(set) var remoteVideoTrack: RTCVideoTrack?
    
    private var videoCapturer: RTCVideoCapturer?
    private var videoSource: RTCVideoSource?
    
    @Published var callState: CallState = .idle
    @Published var callDuration: TimeInterval = 0
    @Published var isVideoEnabled: Bool = false
    @Published var isRemoteVideoEnabled: Bool = false
    @Published var cameraPosition: CameraPosition = .front
    
    private var callTimer: Timer?
    private var callStartTime: Date?
    private var incomingCallId: String?
    private var currentCallId: String?
    private var sessionUUID: String?
    private var currentCallUUID: UUID?
    
    // –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–∏–ø–∞ –∑–≤–æ–Ω–∫–∞
    private var currentCallHasVideo: Bool = false
    
    enum CallState: Int {
        case idle = 0
        case incoming = 1
        case connecting = 2
        case connected = 3
    }
    
    enum CameraPosition {
        case front, back
    }
    
    var isInCall: Bool {
        return callState != .idle
    }
    
    private override init() {
        super.init()
        configureAudioSession()
        setupAudioTrack()
        checkCameraPermission()
        print("üîπ WebRTCManager initialized")
    }
    
    // MARK: - Permission Checks
    
    private func checkCameraPermission() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            print("‚úÖ Camera permission granted")
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                print("üìπ Camera permission: \(granted)")
            }
        case .denied, .restricted:
            print("‚ùå Camera permission denied")
        @unknown default:
            break
        }
    }
    
    // MARK: - Audio Track Setup
    
    private func setupAudioTrack() {
        print("üîä Setting up audio track...")
        
        // –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Å—Ç—Ä–µ–π–Ω—Ç—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        let audioSource = factory.audioSource(with: nil)
        
        localAudioTrack = factory.audioTrack(with: audioSource, trackId: "audio0")
        localAudioTrack?.isEnabled = true
        
        print("üîä Local audio track created and enabled")
    }
    
    // MARK: - Video Setup
    
    private func setupVideo() {
        #if !targetEnvironment(simulator)
        print("üé• Setting up video...")
        
        // –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ –∏—Å—Ç–æ—á–Ω–∏–∫
        videoSource = factory.videoSource()
        
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç —Å –∫–∞–º–µ—Ä—ã
        setupCameraCapture()
        
        // –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
        if let videoSource = videoSource {
            localVideoTrack = factory.videoTrack(with: videoSource, trackId: "video0")
            localVideoTrack?.isEnabled = true
            print("üé• Local video track created and enabled")
        }
        #endif
    }
    
    private func setupCameraCapture() {
        #if !targetEnvironment(simulator)
        guard let videoSource = videoSource else { return }
        
        // –í—ã–±–∏—Ä–∞–µ–º —Ñ—Ä–æ–Ω—Ç–∞–ª—å–Ω—É—é –∫–∞–º–µ—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        let discoverySession = AVCaptureDevice.DiscoverySession(
            deviceTypes: [.builtInWideAngleCamera, .builtInTrueDepthCamera],
            mediaType: .video,
            position: .front
        )
        
        guard let cameraDevice = discoverySession.devices.first else {
            print("‚ùå No camera available")
            return
        }
        
        // –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ–∑–∞—Ö–≤–∞—Ç—á–∏–∫
        let capturer = RTCCameraVideoCapturer(delegate: videoSource)
        videoCapturer = capturer
        
        // –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞—Ö–≤–∞—Ç
        let formats = RTCCameraVideoCapturer.supportedFormats(for: cameraDevice)
        guard let format = formats.last else { return }
        
        let fps = format.videoSupportedFrameRateRanges.first?.maxFrameRate ?? 30
        
        capturer.startCapture(with: cameraDevice,
                             format: format,
                             fps: Int(fps))
        
        print("üé• Camera capture started: \(cameraDevice.localizedName)")
        #endif
    }
    
    private func stopVideoCapture() {
        #if !targetEnvironment(simulator)
        if let capturer = videoCapturer as? RTCCameraVideoCapturer {
            capturer.stopCapture()
            print("üé• Video capture stopped")
        }
        videoCapturer = nil
        videoSource = nil
        localVideoTrack = nil
        #endif
    }
    
    func switchCamera() {
        #if !targetEnvironment(simulator)
        guard let capturer = videoCapturer as? RTCCameraVideoCapturer else { return }
        
        // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é –∫–∞–º–µ—Ä—ã
        let newPosition: AVCaptureDevice.Position = cameraPosition == .front ? .back : .front
        cameraPosition = newPosition == .front ? .front : .back
        
        // –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        let discoverySession = AVCaptureDevice.DiscoverySession(
            deviceTypes: [.builtInWideAngleCamera],
            mediaType: .video,
            position: newPosition
        )
        
        if let newDevice = discoverySession.devices.first,
           let format = RTCCameraVideoCapturer.supportedFormats(for: newDevice).last {
            
            let fps = format.videoSupportedFrameRateRanges.first?.maxFrameRate ?? 30
            capturer.startCapture(with: newDevice, format: format, fps: Int(fps))
            
            print("üîÑ Camera switched to: \(newPosition == .front ? "front" : "back")")
        }
        #endif
    }
    
    func toggleVideo() {
        isVideoEnabled.toggle()
        
        if isVideoEnabled {
            // –í–∫–ª—é—á–∞–µ–º –≤–∏–¥–µ–æ
            if localVideoTrack == nil {
                setupVideo()
            }
            
            // –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ –≤ peer connection, –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç
            if let videoTrack = localVideoTrack,
               let pc = peerConnection {
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
                let hasVideoSender = pc.senders.contains { $0.track?.kind == "video" }
                if !hasVideoSender {
                    let sender = pc.add(videoTrack, streamIds: ["stream0"])
                    print("üé• Video track added to peer connection")
                }
            }
        } else {
            // –í—ã–∫–ª—é—á–∞–µ–º –≤–∏–¥–µ–æ - —É–¥–∞–ª—è–µ–º —Ç—Ä–µ–∫ –∏–∑ peer connection
            if let pc = peerConnection {
                let senders = pc.senders
                for sender in senders where sender.track?.kind == "video" {
                    pc.removeTrack(sender)
                    print("üé• Video track removed from peer connection")
                }
            }
        }
    }
    
    // MARK: - Audio Management
    
    func toggleSpeaker() {
        let session = AVAudioSession.sharedInstance()
        do {
            if session.currentRoute.outputs.first?.portType == .builtInSpeaker {
                try session.overrideOutputAudioPort(.none)
                print("üîä Switched to receiver")
            } else {
                try session.overrideOutputAudioPort(.speaker)
                print("üîä Switched to speaker")
            }
        } catch {
            print("‚ùå Failed to toggle speaker: \(error)")
        }
    }
    
    func toggleBluetooth() {
        // –ü—Ä–æ—Å—Ç–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Å–∏—Å—Ç–µ–º–∞ —Å–∞–º–∞ –≤—ã–±–µ—Ä–µ—Ç Bluetooth –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        let session = AVAudioSession.sharedInstance()
        do {
            try session.overrideOutputAudioPort(.none)
            print("üì± Switched to bluetooth/none")
        } catch {
            print("‚ùå Failed to switch audio route: \(error)")
        }
    }
    
    // MARK: - TIME
    
    private func localTimestamp() -> String {
        let formatter = ISO8601DateFormatter()
        formatter.formatOptions = [.withInternetDateTime, .withFractionalSeconds]
        return formatter.string(from: Date())
    }
    
    // MARK: - AUDIO SESSION
    
    private func configureAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setCategory(.playAndRecord,
                                   mode: .voiceChat,
                                   options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP, .mixWithOthers])
            try session.setActive(true)
            RTCAudioSession.sharedInstance().isAudioEnabled = true
            print("üîä AVAudioSession configured")
        } catch {
            print("‚ùå AVAudioSession setup failed: \(error)")
        }
    }
    
    func activateAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setActive(true)
            RTCAudioSession.sharedInstance().isAudioEnabled = true
            print("üîä Audio session activated")
        } catch {
            print("‚ùå Failed to activate audio session: \(error)")
        }
    }
    
    func deactivateAudioSession() {
        let session = AVAudioSession.sharedInstance()
        do {
            try session.setActive(false, options: .notifyOthersOnDeactivation)
            RTCAudioSession.sharedInstance().isAudioEnabled = false
            print("üîá Audio session deactivated")
        } catch {
            print("‚ùå Failed to deactivate audio session: \(error)")
        }
    }
    
    // –ü–æ–ª–Ω—ã–π —Å–±—Ä–æ—Å –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏
    private func resetAudioSession() {
        deactivateAudioSession()
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) { [weak self] in
            self?.configureAudioSession()
        }
    }
    
    // MARK: - CALL MANAGEMENT
    
    func startCall(sessionUUID: String, to peerName: String, withVideo: Bool = false) async {
        guard callState == .idle else { return }
        
        resetAudioSession()
        
        self.sessionUUID = sessionUUID
        self.currentCallId = "\(Date().timeIntervalSince1970)"
        self.currentCallUUID = UUID()
        self.isVideoEnabled = withVideo
        self.currentCallHasVideo = withVideo
        
        print("üìû Starting \(withVideo ? "video" : "audio") call to \(peerName), session: \(sessionUUID)")
        
        activateAudioSession()
        
        DispatchQueue.main.async { self.callState = .connecting }
        
        // –°–æ–∑–¥–∞–µ–º peer connection —Å –≤–∏–¥–µ–æ
        setupPeerConnection(withVideo: withVideo)
        
        // –ï—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ–∑–≤–æ–Ω–æ–∫, —É–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ —Å–æ–∑–¥–∞–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω
        if withVideo && localVideoTrack == nil {
            setupVideo()
            if let videoTrack = localVideoTrack {
                peerConnection?.add(videoTrack, streamIds: ["stream0"])
                print("üé• Video track added to peer connection in startCall")
            }
        }
        
        await createOffer(to: peerName, withVideo: withVideo)
        
        NotificationCenter.default.post(
            name: NSNotification.Name("CallStateChangedNotification"),
            object: nil,
            userInfo: ["state": callState.rawValue]
        )
    }
    
    func receiveCall(sessionUUID: String, callId: String, sdp: String, hasVideo: Bool = false) {
        guard callState == .idle else {
            print("‚ùå Incoming call ignored, another call is active")
            return
        }
        
        resetAudioSession()
        
        self.sessionUUID = sessionUUID
        self.incomingCallId = callId
        self.currentCallUUID = UUID()
        self.isRemoteVideoEnabled = hasVideo
        self.currentCallHasVideo = hasVideo
        
        print("üì• Incoming \(hasVideo ? "video" : "audio") call received | callId: \(callId), session: \(sessionUUID)")
        
        activateAudioSession()
        
        DispatchQueue.main.async { self.callState = .incoming }
        
        // –°–æ–∑–¥–∞–µ–º peer connection —Å —É—á–µ—Ç–æ–º –≤–∏–¥–µ–æ
        setupPeerConnection(withVideo: hasVideo)
        
        // –ï—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ–∑–≤–æ–Ω–æ–∫, —Å–æ–∑–¥–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
        if hasVideo {
            setupVideo()
            if let videoTrack = localVideoTrack {
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
                let hasVideoSender = peerConnection?.senders.contains { $0.track?.kind == "video" } ?? false
                if !hasVideoSender {
                    peerConnection?.add(videoTrack, streamIds: ["stream0"])
                    isVideoEnabled = true
                    print("üé• Video track added to peer connection in receiveCall")
                }
            }
        }
        
        NotificationCenter.default.post(
            name: NSNotification.Name("IncomingCallNotification"),
            object: nil,
            userInfo: [
                "callId": callId,
                "sessionUUID": sessionUUID,
                "from": "–ö–ª–∏–µ–Ω—Ç",
                "hasVideo": hasVideo,
                "timestamp": Date().timeIntervalSince1970
            ]
        )
        
        let remoteSDP = RTCSessionDescription(type: .offer, sdp: sdp)
        peerConnection?.setRemoteDescription(remoteSDP) { [weak self] error in
            if let error = error {
                print("‚ùå setRemoteDescription failed: \(error)")
            } else {
                print("‚úÖ Remote SDP set for incoming call")
            }
        }
    }
    
    func answerCall(to peerName: String) async {
        guard let pc = peerConnection, let callId = incomingCallId else {
            print("‚ùå Cannot answer call: peerConnection or callId is nil")
            return
        }
        
        print("üìû Answering call, hasVideo: \(currentCallHasVideo)")
        
        // –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∞—É–¥–∏–æ —Ç—Ä–µ–∫ –≤–∫–ª—é—á–µ–Ω
        localAudioTrack?.isEnabled = true
        
        let constraints = RTCMediaConstraints(
            mandatoryConstraints: [
                "OfferToReceiveAudio": "true",
                "OfferToReceiveVideo": currentCallHasVideo ? "true" : "false"
            ],
            optionalConstraints: nil
        )
        
        do {
            let answer = try await pc.answer(for: constraints)
            try await pc.setLocalDescription(answer)
            
            let payload: [String: Any] = [
                "type": "call_answer",
                "sdp": answer.sdp,
                "from": "iOSAdmin",
                "to": peerName,
                "callId": callId,
                "session_uuid": sessionUUID ?? "",
                "hasVideo": currentCallHasVideo,
                "timestamp": localTimestamp()
            ]
            WebSocketService.shared.send(dictionary: payload)
            
            currentCallId = callId
            incomingCallId = nil
            
            DispatchQueue.main.async {
                self.callState = .connected
                self.startCallTimer()
                print("‚úÖ Call answered, connected to \(peerName)")
                
                NotificationCenter.default.post(
                    name: NSNotification.Name("CallStateChangedNotification"),
                    object: nil,
                    userInfo: ["state": self.callState.rawValue]
                )
                
                if self.currentCallHasVideo {
                    NotificationCenter.default.post(
                        name: NSNotification.Name("VideoCallConnectedNotification"),
                        object: nil,
                        userInfo: nil
                    )
                }
            }
            
            NotificationCenter.default.post(
                name: NSNotification.Name("CallAcceptedNotification"),
                object: nil,
                userInfo: ["peerName": peerName, "hasVideo": currentCallHasVideo]
            )
        } catch {
            print("‚ùå Answer failed: \(error)")
        }
    }
    
    func setRemoteAnswer(sdp: String) async {
        guard let pc = peerConnection else { return }
        let remoteSDP = RTCSessionDescription(type: .answer, sdp: sdp)
        do {
            try await pc.setRemoteDescription(remoteSDP)
            
            // –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∞—É–¥–∏–æ —Ç—Ä–µ–∫ –≤–∫–ª—é—á–µ–Ω –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            DispatchQueue.main.async {
                self.remoteAudioTrack?.isEnabled = true
                self.localAudioTrack?.isEnabled = true
                
                self.callState = .connected
                self.startCallTimer()
                print("‚úÖ Remote answer applied, call connected")
                
                NotificationCenter.default.post(
                    name: NSNotification.Name("CallStateChangedNotification"),
                    object: nil,
                    userInfo: ["state": self.callState.rawValue]
                )
            }
        } catch {
            print("‚ùå Set remote answer failed: \(error)")
        }
    }
    
    func addRemoteIceCandidate(_ candidate: RTCIceCandidate) {
        peerConnection?.add(candidate)
        print("üîπ Remote ICE candidate added")
    }
    
    func endCall(to peerName: String? = nil) {
        let activeSession = sessionUUID
        let finalDuration = Int(callDuration)
        let hadVideo = currentCallHasVideo
        
        stopCallTimer()
        DispatchQueue.main.async { self.callState = .idle }
        
        if let sessionUUID = activeSession, finalDuration > 0, callStartTime != nil {
            WebSocketService.shared.sendCallLogMessage(
                sessionUUID: sessionUUID,
                duration: finalDuration
            )
            print("üìû Call ended, duration: \(finalDuration)s")
        }
        
        NotificationCenter.default.post(
            name: NSNotification.Name("CallStateChangedNotification"),
            object: nil,
            userInfo: ["state": callState.rawValue]
        )
        
        cleanup()
        
        if let peerName = peerName, let sessionUUID = activeSession {
            let payload: [String: Any] = [
                "type": "call_end",
                "from": "iOSAdmin",
                "to": peerName,
                "session_uuid": sessionUUID,
                "timestamp": localTimestamp()
            ]
            WebSocketService.shared.send(dictionary: payload)
        }
        
        NotificationCenter.default.post(
            name: NSNotification.Name("CallEndedNotification"),
            object: nil,
            userInfo: ["hadVideo": hadVideo]
        )
        
        print("üì¥ Call ended")
    }
    
    private func cleanup() {
        peerConnection?.close()
        peerConnection = nil
        
        stopVideoCapture()
        
        remoteAudioTrack = nil
        remoteVideoTrack = nil
        
        incomingCallId = nil
        currentCallId = nil
        sessionUUID = nil
        callStartTime = nil
        currentCallUUID = nil
        isVideoEnabled = false
        isRemoteVideoEnabled = false
        currentCallHasVideo = false
        
        DispatchQueue.main.async { [weak self] in
            self?.resetAudioSession()
        }
    }
    
    // MARK: - PEER CONNECTION
    
    private func setupPeerConnection(withVideo: Bool = false) {
        let config = RTCConfiguration()
        config.sdpSemantics = .unifiedPlan
        
        config.iceServers = [
            RTCIceServer(urlStrings: ["turn:77.41.177.55:3478?transport=udp"], username: "DUSTBG", credential: "DUSTISROOT"),
            RTCIceServer(urlStrings: ["turn:77.41.177.55:3478?transport=tcp"], username: "DUSTBG", credential: "DUSTISROOT"),
            RTCIceServer(urlStrings: ["turns:77.41.177.55:443?transport=tcp"], username: "DUSTBG", credential: "DUSTISROOT"),
            RTCIceServer(urlStrings: ["stun:stun.l.google.com:19302"])
        ]
        
        config.iceTransportPolicy = .all
        config.iceCandidatePoolSize = 10
        
        let constraints = RTCMediaConstraints(mandatoryConstraints: nil, optionalConstraints: nil)
        peerConnection = factory.peerConnection(with: config, constraints: constraints, delegate: self)
        
        // –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ —Ç—Ä–µ–∫ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        if let audioTrack = localAudioTrack {
            audioTrack.isEnabled = true
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∞—É–¥–∏–æ —Ç—Ä–µ–∫
            let hasAudioSender = peerConnection?.senders.contains { $0.track?.kind == "audio" } ?? false
            if !hasAudioSender {
                let audioSender = peerConnection?.add(audioTrack, streamIds: ["stream0"])
                print("üîä Audio track added to peer connection, sender: \(audioSender != nil)")
            } else {
                print("üîä Audio track already exists in peer connection")
            }
        } else {
            print("‚ùå Local audio track is nil, recreating...")
            setupAudioTrack()
            if let audioTrack = localAudioTrack {
                peerConnection?.add(audioTrack, streamIds: ["stream0"])
                print("üîä Audio track recreated and added")
            }
        }
        
        // –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ —Å—Ä–∞–∑—É, –µ—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ–∑–≤–æ–Ω–æ–∫
        if withVideo {
            print("üé• Setting up video for peer connection...")
            
            // –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫
            if localVideoTrack == nil {
                setupVideo()
            }
            
            // –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫ –≤ peer connection
            if let videoTrack = localVideoTrack {
                videoTrack.isEnabled = true
                let hasVideoSender = peerConnection?.senders.contains { $0.track?.kind == "video" } ?? false
                if !hasVideoSender {
                    let videoSender = peerConnection?.add(videoTrack, streamIds: ["stream0"])
                    isVideoEnabled = true
                    print("üé• Video track added to peer connection, sender: \(videoSender != nil)")
                } else {
                    print("üé• Video track already exists in peer connection")
                }
            } else {
                print("‚ùå Failed to create video track")
            }
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç—Ä–µ–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã
        if let pc = peerConnection {
            let senders = pc.senders
            print("üì§ Peer connection senders after setup: \(senders.map { $0.track?.kind ?? "unknown" })")
            
            // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ
            if senders.first(where: { $0.track?.kind == "audio" }) == nil {
                print("‚ö†Ô∏è No audio sender found, trying to add again...")
                if let audioTrack = localAudioTrack {
                    peerConnection?.add(audioTrack, streamIds: ["stream0"])
                }
            }
        }
        
        print("üîπ PeerConnection setup complete" + (withVideo ? " with video" : ""))
    }
    
    private func createOffer(to peerName: String, withVideo: Bool) async {
        guard let pc = peerConnection, let sessionUUID = sessionUUID, let callId = currentCallId else {
            print("‚ùå Cannot create offer: missing parameters")
            return
        }
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —Ç—Ä–µ–∫–∏ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º offer
        let senders = pc.senders
        print("üì§ Creating offer with senders: \(senders.map { $0.track?.kind ?? "unknown" })")
        
        // –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∞—É–¥–∏–æ —Ç—Ä–µ–∫ –≤–∫–ª—é—á–µ–Ω
        localAudioTrack?.isEnabled = true
        
        let constraints = RTCMediaConstraints(
            mandatoryConstraints: [
                "OfferToReceiveAudio": "true",
                "OfferToReceiveVideo": withVideo ? "true" : "false"
            ],
            optionalConstraints: nil
        )
        
        do {
            let offer = try await pc.offer(for: constraints)
            try await pc.setLocalDescription(offer)
            
            let payload: [String: Any] = [
                "type": "call_offer",
                "from": "iOSAdmin",
                "to": peerName,
                "sdp": offer.sdp,
                "callId": callId,
                "session_uuid": sessionUUID,
                "hasVideo": withVideo,
                "timestamp": localTimestamp()
            ]
            WebSocketService.shared.send(dictionary: payload)
            print("üì§ Call offer sent to \(peerName), hasVideo: \(withVideo)")
        } catch {
            print("‚ùå Offer failed: \(error)")
        }
    }
    
    // MARK: - CALL TIMER
    
    private func startCallTimer() {
        callStartTime = Date()
        DispatchQueue.main.async {
            self.callDuration = 0
            self.callTimer = Timer.scheduledTimer(withTimeInterval: 1, repeats: true) { [weak self] _ in
                self?.callDuration += 1
            }
        }
    }
    
    private func stopCallTimer() {
        callTimer?.invalidate()
        callTimer = nil
        DispatchQueue.main.async { self.callDuration = 0 }
    }
    
    // MARK: - –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´
    
    func declineCall() {
        if let callId = incomingCallId {
            let payload: [String: Any] = [
                "type": "call_reject",
                "callId": callId,
                "from": "iOSAdmin",
                "session_uuid": sessionUUID ?? "",
                "timestamp": localTimestamp()
            ]
            WebSocketService.shared.send(dictionary: payload)
        }
        
        NotificationCenter.default.post(
            name: NSNotification.Name("CallDeclinedNotification"),
            object: nil
        )
        
        stopCallTimer()
        DispatchQueue.main.async { self.callState = .idle }
        
        NotificationCenter.default.post(
            name: NSNotification.Name("CallStateChangedNotification"),
            object: nil,
            userInfo: ["state": callState.rawValue]
        )
        
        cleanup()
        
        print("üì¥ Call declined")
    }
}

// MARK: - PEER CONNECTION DELEGATE

extension WebRTCManager: RTCPeerConnectionDelegate {
    func peerConnection(_ peerConnection: RTCPeerConnection, didChange stateChanged: RTCSignalingState) {}
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didAdd rtpReceiver: RTCRtpReceiver, streams: [RTCMediaStream]) {
        print("üì• didAdd rtpReceiver, streams count: \(streams.count)")
        
        for stream in streams {
            print("   Stream id: \(stream.streamId)")
            print("   Video tracks: \(stream.videoTracks.count)")
            print("   Audio tracks: \(stream.audioTracks.count)")
            
            // –ü–æ–ª—É—á–∞–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫–∏
            if let videoTrack = stream.videoTracks.first {
                DispatchQueue.main.async {
                    self.remoteVideoTrack = videoTrack
                    self.remoteVideoTrack?.isEnabled = true
                    self.isRemoteVideoEnabled = true
                    print("üé• Remote video track received and set from rtpReceiver")
                    
                    NotificationCenter.default.post(
                        name: NSNotification.Name("RemoteVideoTrackReceived"),
                        object: nil,
                        userInfo: ["track": videoTrack]
                    )
                }
            }
            
            // –í–ê–ñ–ù–û: –ü–æ–ª—É—á–∞–µ–º –∏ –≤–∫–ª—é—á–∞–µ–º –∞—É–¥–∏–æ —Ç—Ä–µ–∫–∏
            if let audioTrack = stream.audioTracks.first {
                DispatchQueue.main.async {
                    self.remoteAudioTrack = audioTrack
                    self.remoteAudioTrack?.isEnabled = true
                    print("üîä Remote audio track received and ENABLED")
                    
                    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
                    if let audioTrack = self.remoteAudioTrack {
                        print("üîä Remote audio track - isEnabled: \(audioTrack.isEnabled)")
                    }
                }
            }
        }
    }
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didAdd stream: RTCMediaStream) {
        print("üì• didAdd stream: \(stream.streamId)")
        print("   - Video tracks: \(stream.videoTracks.count)")
        print("   - Audio tracks: \(stream.audioTracks.count)")
        
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∏–¥–µ–æ —Ç—Ä–µ–∫–∏
        if let videoTrack = stream.videoTracks.first {
            DispatchQueue.main.async {
                self.remoteVideoTrack = videoTrack
                self.remoteVideoTrack?.isEnabled = true
                self.isRemoteVideoEnabled = true
                print("üé• Remote video stream received and set")
                
                NotificationCenter.default.post(
                    name: NSNotification.Name("RemoteVideoTrackReceived"),
                    object: nil,
                    userInfo: ["track": videoTrack]
                )
            }
        }
        
        // –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –≤–∫–ª—é—á–∞–µ–º –∞—É–¥–∏–æ —Ç—Ä–µ–∫–∏
        if let audioTrack = stream.audioTracks.first {
            DispatchQueue.main.async {
                self.remoteAudioTrack = audioTrack
                self.remoteAudioTrack?.isEnabled = true
                print("üîä Remote audio stream received and ENABLED")
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å
                print("üîä Remote audio track - isEnabled: \(audioTrack.isEnabled)")
            }
        }
    }
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didRemove stream: RTCMediaStream) {
        print("üì§ Stream removed: \(stream.streamId)")
        if stream.videoTracks.first != nil {
            DispatchQueue.main.async {
                self.isRemoteVideoEnabled = false
                self.remoteVideoTrack = nil
            }
        }
        if stream.audioTracks.first != nil {
            DispatchQueue.main.async {
                self.remoteAudioTrack = nil
                print("üîä Remote audio track removed")
            }
        }
    }
    
    func peerConnectionShouldNegotiate(_ peerConnection: RTCPeerConnection) {}
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didChange newState: RTCIceConnectionState) {
        print("üßä ICE state changed: \(newState.rawValue)")
        
        switch newState {
        case .connected:
            print("‚úÖ ICE connected - media should flow")
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã–µ —Ç—Ä–µ–∫–∏
            let senders = peerConnection.senders
            print("üì§ Active senders: \(senders.map { $0.track?.kind ?? "unknown" })")
            
            // –í–ê–ñ–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –∞—É–¥–∏–æ —Ç—Ä–µ–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã
            DispatchQueue.main.async {
                self.localAudioTrack?.isEnabled = true
                self.remoteAudioTrack?.isEnabled = true
                print("üîä Audio tracks enabled after ICE connected")
            }
            
        case .disconnected, .failed, .closed:
            print("‚ö†Ô∏è ICE connection lost, ending call")
            DispatchQueue.main.async {
                if self.callState != .idle {
                    self.endCall()
                }
            }
        default:
            break
        }
    }
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didChange newState: RTCIceGatheringState) {}
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didGenerate candidate: RTCIceCandidate) {
        guard let sessionUUID = sessionUUID, let callId = currentCallId else { return }
        let payload: [String: Any] = [
            "type": "ice_candidate",
            "candidate": [
                "candidate": candidate.sdp,
                "sdpMLineIndex": candidate.sdpMLineIndex,
                "sdpMid": candidate.sdpMid ?? ""
            ],
            "from": "iOSAdmin",
            "session_uuid": sessionUUID,
            "callId": callId,
            "timestamp": localTimestamp()
        ]
        WebSocketService.shared.send(dictionary: payload)
        print("üì° Local ICE candidate sent")
    }
    
    func peerConnection(_ peerConnection: RTCPeerConnection, didRemove candidates: [RTCIceCandidate]) {}
    func peerConnection(_ peerConnection: RTCPeerConnection, didOpen dataChannel: RTCDataChannel) {}
}
